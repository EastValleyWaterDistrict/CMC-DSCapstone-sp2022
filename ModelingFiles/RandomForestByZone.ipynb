{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest By Zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      \n",
    "import pandas as pd    \n",
    "from IPython.display import display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../CleanedData/MountainCat.csv : file read into a pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Read in the data \n",
    "filename = '../CleanedData/MountainCat.csv'\n",
    "all_data = pd.read_csv(filename)      \n",
    "print(f\"{filename} : file read into a pandas dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL_INDEX is {'Precip (in)': 0, 'Max Air Temp (F)': 1, 'Min Air Temp (F)': 2, 'Max Rel Hum (%)': 3, 'Min Rel Hum (%)': 4, 'Avg Wind Speed (mph)': 5, 'T1': 6, 'T2': 7, 'T7': 8, 'T14': 9, 'T21': 10, 'Consumption': 11}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "COLUMNS = all_data.columns            # \"list\" of columns\n",
    "\n",
    "# let's create a dictionary to look up any column index by name\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX is {COL_INDEX}\\n\\n\")\n",
    "\n",
    "ClassNames = []\n",
    "\n",
    "for num in range(131):\n",
    "    ClassNames += [str(num)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tidy.shape is (545, 12)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 545 entries, 0 to 544\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Precip (in)           545 non-null    float64\n",
      " 1   Max Air Temp (F)      545 non-null    float64\n",
      " 2   Min Air Temp (F)      545 non-null    float64\n",
      " 3   Max Rel Hum (%)       545 non-null    int64  \n",
      " 4   Min Rel Hum (%)       545 non-null    int64  \n",
      " 5   Avg Wind Speed (mph)  545 non-null    float64\n",
      " 6   T1                    545 non-null    int64  \n",
      " 7   T2                    545 non-null    int64  \n",
      " 8   T7                    545 non-null    int64  \n",
      " 9   T14                   545 non-null    int64  \n",
      " 10  T21                   545 non-null    int64  \n",
      " 11  Consumption           545 non-null    int64  \n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 55.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Max Air Temp (F)</th>\n",
       "      <th>Min Air Temp (F)</th>\n",
       "      <th>Max Rel Hum (%)</th>\n",
       "      <th>Min Rel Hum (%)</th>\n",
       "      <th>Avg Wind Speed (mph)</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T7</th>\n",
       "      <th>T14</th>\n",
       "      <th>T21</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>86.7</td>\n",
       "      <td>56.7</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>86.6</td>\n",
       "      <td>53.4</td>\n",
       "      <td>87</td>\n",
       "      <td>33</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>80.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>98</td>\n",
       "      <td>44</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>76.3</td>\n",
       "      <td>58.1</td>\n",
       "      <td>88</td>\n",
       "      <td>49</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>74.7</td>\n",
       "      <td>59.7</td>\n",
       "      <td>84</td>\n",
       "      <td>49</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.01</td>\n",
       "      <td>67.3</td>\n",
       "      <td>43.3</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.01</td>\n",
       "      <td>71.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.04</td>\n",
       "      <td>73.5</td>\n",
       "      <td>42.1</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.05</td>\n",
       "      <td>74.0</td>\n",
       "      <td>43.7</td>\n",
       "      <td>76</td>\n",
       "      <td>30</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.04</td>\n",
       "      <td>67.9</td>\n",
       "      <td>47.2</td>\n",
       "      <td>85</td>\n",
       "      <td>47</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precip (in)  Max Air Temp (F)  Min Air Temp (F)  Max Rel Hum (%)  \\\n",
       "0           0.00              86.7              56.7               78   \n",
       "1           0.00              86.6              53.4               87   \n",
       "2           0.00              80.2              55.8               98   \n",
       "3           0.00              76.3              58.1               88   \n",
       "4           0.00              74.7              59.7               84   \n",
       "..           ...               ...               ...              ...   \n",
       "540         0.01              67.3              43.3               91   \n",
       "541         0.01              71.6              36.5               55   \n",
       "542         0.04              73.5              42.1               65   \n",
       "543         0.05              74.0              43.7               76   \n",
       "544         0.04              67.9              47.2               85   \n",
       "\n",
       "     Min Rel Hum (%)  Avg Wind Speed (mph)  T1  T2  T7  T14  T21  Consumption  \n",
       "0                 29                   2.9   6   6   6    6    6            6  \n",
       "1                 33                   2.8   7   7   7    7    7            7  \n",
       "2                 44                   3.4   6   6   6    6    6            6  \n",
       "3                 49                   3.8   6   6   6    6    6            6  \n",
       "4                 49                   3.5   6   6   6    6    6            6  \n",
       "..               ...                   ...  ..  ..  ..  ...  ...          ...  \n",
       "540               10                   7.9   5   5   5    5    5            5  \n",
       "541               13                   4.1   6   6   6    6    6            6  \n",
       "542               20                   4.1   6   6   6    6    6            6  \n",
       "543               30                   3.9   6   6   6    6    6            6  \n",
       "544               47                   4.8   6   6   6    6    6            6  \n",
       "\n",
       "[545 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data \n",
    "print(f\"df_tidy.shape is {all_data.shape}\\n\")\n",
    "all_data.info()  # prints column information\n",
    "\n",
    "display(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00e+00 8.67e+01 5.67e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [0.00e+00 8.66e+01 5.34e+01 ... 7.00e+00 7.00e+00 7.00e+00]\n",
      " [0.00e+00 8.02e+01 5.58e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " ...\n",
      " [4.00e-02 7.35e+01 4.21e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [5.00e-02 7.40e+01 4.37e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [4.00e-02 6.79e+01 4.72e+01 ... 6.00e+00 6.00e+00 6.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to array\n",
    "A = all_data.to_numpy()   \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00e+00 8.67e+01 5.67e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [0.00e+00 8.66e+01 5.34e+01 ... 7.00e+00 7.00e+00 7.00e+00]\n",
      " [0.00e+00 8.02e+01 5.58e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " ...\n",
      " [4.00e-02 7.35e+01 4.21e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [5.00e-02 7.40e+01 4.37e+01 ... 6.00e+00 6.00e+00 6.00e+00]\n",
      " [4.00e-02 6.79e+01 4.72e+01 ... 6.00e+00 6.00e+00 6.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to float\n",
    "A = A.astype('float64')  \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 545 rows and 12 cols\n"
     ]
    }
   ],
   "source": [
    "# Get the num of rows and columns\n",
    "NUM_ROWS, NUM_COLS = A.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "X_all = A[:,0:NUM_COLS-1]  # X (features) \n",
    "y_all = A[:,NUM_COLS-1]    # y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scrambled labels/species are \n",
      " [ 5.  6.  6.  3.  4.  9.  3.  8.  8.  9.  9.  3.  8.  9.  6.  5.  9. 10.\n",
      "  4.  8.  4.  5.  9. 10. 10.  6.  3.  4. 10.  5.  6.  3.  5.  5.  6.  6.\n",
      "  8.  2.  9.  6.  6.  6.  6.  6.  8.  7.  7.  5.  4.  3.  6.  6.  5.  6.\n",
      "  8.  6.  9.  6.  3.  2.  9.  5.  5.  3.  3.  5.  5.  8.  5.  9.  6.  9.\n",
      "  6.  8.  7.  8.  9.  9.  9.  3.  8.  4.  7.  7.  9.  8.  3.  8.  9.  6.\n",
      "  7.  9. 10.  3.  7.  6.  4.  3.  4. 10.  5.  6.  6.  8.  9.  4.  8.  3.\n",
      "  2.  3.  5.  5.  5.  3. 11.  6.  8.  6.  7.  5.  9. 10.  9.  8. 10.  5.\n",
      "  6.  6. 10.  6.  7.  5.  6.  8.  8.  5.  4. 10.  6.  4.  4.  5.  9.  3.\n",
      "  6.  6. 10.  6.  8. 10.  6.  6.  4.  7.  8.  6.  3.  4.  5.  9.  4. 10.\n",
      " 10. 10.  6.  6.  6.  8.  4.  9. 10.  5.  4. 10. 10.  9.  6.  8.  7.  6.\n",
      "  6.  6.  6.  6.  6.  5.  6.  4.  6.  6.  7.  8.  6.  6.  6.  6.  3.  4.\n",
      "  6.  4.  5.  3.  6.  5.  5.  8.  4.  9.  8.  7.  4.  6.  7.  6.  6.  8.\n",
      "  4.  6.  7.  6.  4.  6.  7.  9.  9.  3.  8.  7.  5.  4.  9.  3.  6.  4.\n",
      "  5.  4.  6.  7.  8.  8.  8.  5.  4.  9.  5.  4.  3.  8.  6.  4.  5.  4.\n",
      "  6.  9.  8.  5.  7.  6.  6.  3.  6.  6.  8.  7.  4.  5. 10.  3.  5.  5.\n",
      "  6.  3.  4.  7.  4.  4.  2.  9.  9.  6.  5. 10.  5.  3. 11.  9.  3.  4.\n",
      "  9.  4.  7. 10.  9.  9.  8.  5.  9.  6.  5.  6.  6.  4.  7.  4.  9. 10.\n",
      "  6.  5.  6.  7.  3.  5.  3.  3.  5.  6.  6. 10.  5.  3.  5.  6.  6.  9.\n",
      " 11.  4.  4.  6.  7.  6.  3.  9.  5.  9.  5.  3.  6.  5.  5.  9.  5.  6.\n",
      "  4. 10. 10.  8.  5. 10.  4.  4.  9.  6.  5.  5.  8.  5.  5.  6.  4.  5.\n",
      "  7.  4.  5.  5.  7.  6.  3.  5.  3.  8.  9.  6.  7.  5.  5.  9.  6.  6.\n",
      "  3.  8.  9.  7.  6.  3.  8.  5.  6.  3.  9.  5.  6.  2.  6.  3.  6.  7.\n",
      "  4.  5.  5.  5.  8.  4.  2.  7.  4.  6.  5.  6.  8.  7.  6.  3.  6.  4.\n",
      "  6.  4.  6.  7.  5.  5.  4.  6.  9.  2.  5.  6. 10.  7.  4.  6.  6.  6.\n",
      "  5.  4.  7.  3.  6.  6.  8.  5.  9.  8.  6. 10.  8.  9.  6.  6.  4.  2.\n",
      "  7.  6.  9.  7.  6.  6.  8.  5.  9.  4.  3.  6.  6.  9.  9.  5.  5.  9.\n",
      "  5.  3.  6.  9.  6.  9.  4. 10.  2.  5.  3.  6.  5.  7.  8. 10.  6.  5.\n",
      "  7.  6.  6.  7.  6.  7. 10.  6.  9.  4.  7.  6.  5.  5.  9.  7.  6.  9.\n",
      "  6.  7.  6.  6.  9.  8.  4. 10.  7.  7.  9.  6.  9.  5.  7.  8.  5.  6.\n",
      "  9.  6.  3.  9.  3.  8.  5.  7.  6.  6.  4.  2.  7.  6.  6.  9.  8.  5.\n",
      "  7.  6.  3.  7.  6.]\n",
      "The corresponding data rows are \n",
      " [[ 0.  65.5 50.3 87.  43.   5.4  5.   5.   5.   5.   5. ]\n",
      " [ 0.  59.4 42.2 76.  13.   3.4  6.   6.   6.   6.   6. ]\n",
      " [ 0.  73.2 58.2 86.  43.   6.2  6.   6.   6.   6.   6. ]\n",
      " [ 0.  75.5 38.4 74.  24.   2.3  3.   3.   3.   3.   3. ]\n",
      " [ 0.  62.2 42.4 90.  49.   3.2  4.   4.   4.   4.   4. ]]\n"
     ]
    }
   ],
   "source": [
    "# Scramble the data to remove (potential) dependence on its ordering: \n",
    "\n",
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "X_permed = X_all[indices]              \n",
    "y_permed = y_all[indices]              \n",
    "print(f\"The scrambled labels/species are \\n {y_permed}\")\n",
    "print(f\"The corresponding data rows are \\n {X_permed[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 436 rows;  testing with 109 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seperate data into test data and training data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare labels\n",
    "\n",
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    NUM_LABELS = len(predicted_labels)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            num_correct += 1  # and we count a match!\n",
    "\n",
    "       \n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "    return num_correct\n",
    "\n",
    "# let's try it out!\n",
    "# compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.3899\n",
      "depth:  2  cv accuracy:  0.6353\n",
      "depth:  3  cv accuracy:  0.8073\n",
      "depth:  4  cv accuracy:  0.9931\n",
      "depth:  5  cv accuracy:  1.0000\n",
      "depth:  6  cv accuracy:  1.0000\n",
      "depth:  7  cv accuracy:  1.0000\n",
      "depth:  8  cv accuracy:  1.0000\n",
      "depth:  9  cv accuracy:  1.0000\n",
      "depth: 10  cv accuracy:  1.0000\n",
      "depth: 11  cv accuracy:  1.0000\n",
      "depth: 12  cv accuracy:  1.0000\n",
      "depth: 13  cv accuracy:  1.0000\n",
      "depth: 14  cv accuracy:  1.0000\n",
      "depth: 15  cv accuracy:  1.0000\n",
      "depth: 16  cv accuracy:  1.0000\n",
      "depth: 17  cv accuracy:  1.0000\n",
      "depth: 18  cv accuracy:  1.0000\n",
      "depth: 19  cv accuracy:  1.0000\n",
      "\n",
      "best_depth = 5 is our choice for an underfitting/overfitting balance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/jenniferzecena/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use cross validation to compare different tree-depths\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree \n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "\n",
    "best_d = 1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for d in range(1,20):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   # for each depth, d\n",
    "    cv_scores = cross_val_score( cv_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "    # print(cv_scores)  # we usually don't want to see the five individual scores \n",
    "    average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_d = d\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth\n",
    "best_depth = best_d   # may have to hand-tune this, depending on what happens...\n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for an underfitting/overfitting balance.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a DT classifier with max depth = 5\n"
     ]
    }
   ],
   "source": [
    "# Use the best Depth to build a new model \n",
    "\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_tuned = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [ 8.  7.  7.  7.  4.  7.  5.  9.  5.  3.  5.  6.  3.  3.  4.  6.  6.  6.\n",
      "  6.  4.  3.  7.  6.  7.  9.  6.  4.  7.  6.  6.  3.  6.  5.  6.  3.  9.\n",
      "  6.  3.  7.  5.  4.  6.  5.  8.  4. 10.  6.  5.  4.  5.  6.  5.  9.  8.\n",
      "  3.  6.  6.  5.  8.  4.  8.  6.  8.  5.  9.  6.  3.  6.  9.  5.  6.  3.\n",
      "  5.  6.  3.  5.  9.  8.  5.  4.  6.  9.  3.  5.  6.  7.  5.  8.  6.  5.\n",
      " 10.  5.  6.  8.  7.  4.  6.  5.  3.  4.  5.  6.  8.  5.  6.  6.  7.  6.\n",
      "  5.]\n",
      "Actual labels: [ 8.  7.  7.  7.  4.  7.  5.  9.  5.  3.  5.  6.  3.  3.  4.  6.  6.  6.\n",
      "  6.  4.  3.  7.  6.  7.  9.  6.  4.  7.  6.  6.  3.  6.  5.  6.  3.  9.\n",
      "  6.  3.  7.  5.  4.  6.  5.  8.  4. 10.  6.  5.  4.  5.  6.  5.  9.  8.\n",
      "  3.  6.  6.  5.  8.  4.  8.  6.  8.  5.  9.  6.  3.  6.  9.  5.  6.  3.\n",
      "  5.  6.  3.  5.  9.  8.  5.  4.  6.  9.  3.  5.  6.  7.  5.  8.  6.  5.\n",
      " 10.  5.  6.  8.  7.  4.  6.  5.  3.  4.  5.  6.  8.  5.  6.  6.  7.  6.\n",
      "  5.]\n",
      "\n",
      "\n",
      "Correct: 109 out of 109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = dtree_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "print()\n",
    "\n",
    "# and, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file tree_data.gv written. Try pasting its contents to  http://viz-js.com/\n",
      "\n",
      "digraph Tree {\n",
      "node [shape=box, style=\"filled\", color=\"black\"] ;\n",
      "graph [ranksep=equally, splines=polyline] ;\n",
      "0 [label=\"T1 <= 5.5\\ngini = 0.86\\nsamples = 436\\nvalue = [10, 35, 49, 63, 107, 40, 41, 58, 30, 3]\\nclass = 4\", fillcolor=\"#e8fcf8\"] ;\n",
      "1 [label=\"T21 <= 4.5\\ngini = 0.688\\nsamples = 157\\nvalue = [10, 35, 49, 63, 0, 0, 0, 0, 0, 0]\\nclass = 3\", fillcolor=\"#e5fcea\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"T14 <= 3.5\\ngini = 0.578\\nsamples = 94\\nvalue = [10, 35, 49, 0, 0, 0, 0, 0, 0, 0]\\nclass = 2\", fillcolor=\"#e0f9d0\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"T7 <= 2.5\\ngini = 0.346\\nsamples = 45\\nvalue = [10, 35, 0, 0, 0, 0, 0, 0, 0, 0]\\nclass = 1\", fillcolor=\"#eaec72\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nclass = 0\", fillcolor=\"#e58139\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=\"gini = 0.0\\nsamples = 35\\nvalue = [0, 35, 0, 0, 0, 0, 0, 0, 0, 0]\\nclass = 1\", fillcolor=\"#e2e539\"] ;\n",
      "3 -> 5 ;\n",
      "6 [label=\"gini = 0.0\\nsamples = 49\\nvalue = [0, 0, 49, 0, 0, 0, 0, 0, 0, 0]\\nclass = 2\", fillcolor=\"#7be539\"] ;\n",
      "2 -> 6 ;\n",
      "7 [label=\"gini = 0.0\\nsamples = 63\\nvalue = [0, 0, 0, 63, 0, 0, 0, 0, 0, 0]\\nclass = 3\", fillcolor=\"#39e55e\"] ;\n",
      "1 -> 7 ;\n",
      "8 [label=\"T2 <= 6.5\\ngini = 0.756\\nsamples = 279\\nvalue = [0, 0, 0, 0, 107, 40, 41, 58, 30, 3]\\nclass = 4\", fillcolor=\"#d3f9f2\"] ;\n",
      "0 -> 8 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "9 [label=\"gini = 0.0\\nsamples = 107\\nvalue = [0, 0, 0, 0, 107, 0, 0, 0, 0, 0]\\nclass = 4\", fillcolor=\"#39e5c5\"] ;\n",
      "8 -> 9 ;\n",
      "10 [label=\"T2 <= 8.5\\ngini = 0.745\\nsamples = 172\\nvalue = [0, 0, 0, 0, 0, 40, 41, 58, 30, 3]\\nclass = 7\", fillcolor=\"#f3e5fc\"] ;\n",
      "8 -> 10 ;\n",
      "11 [label=\"T1 <= 7.5\\ngini = 0.5\\nsamples = 81\\nvalue = [0, 0, 0, 0, 0, 40, 41, 0, 0, 0]\\nclass = 6\", fillcolor=\"#fafafe\"] ;\n",
      "10 -> 11 ;\n",
      "12 [label=\"gini = 0.0\\nsamples = 40\\nvalue = [0, 0, 0, 0, 0, 40, 0, 0, 0, 0]\\nclass = 5\", fillcolor=\"#399de5\"] ;\n",
      "11 -> 12 ;\n",
      "13 [label=\"gini = 0.0\\nsamples = 41\\nvalue = [0, 0, 0, 0, 0, 0, 41, 0, 0, 0]\\nclass = 6\", fillcolor=\"#3c39e5\"] ;\n",
      "11 -> 13 ;\n",
      "14 [label=\"T2 <= 9.5\\ngini = 0.484\\nsamples = 91\\nvalue = [0, 0, 0, 0, 0, 0, 0, 58, 30, 3]\\nclass = 7\", fillcolor=\"#d5a4f3\"] ;\n",
      "10 -> 14 ;\n",
      "15 [label=\"gini = 0.0\\nsamples = 58\\nvalue = [0, 0, 0, 0, 0, 0, 0, 58, 0, 0]\\nclass = 7\", fillcolor=\"#a339e5\"] ;\n",
      "14 -> 15 ;\n",
      "16 [label=\"T1 <= 10.5\\ngini = 0.165\\nsamples = 33\\nvalue = [0, 0, 0, 0, 0, 0, 0, 0, 30, 3]\\nclass = 8\", fillcolor=\"#e84dc6\"] ;\n",
      "14 -> 16 ;\n",
      "17 [label=\"gini = 0.0\\nsamples = 30\\nvalue = [0, 0, 0, 0, 0, 0, 0, 0, 30, 0]\\nclass = 8\", fillcolor=\"#e539c0\"] ;\n",
      "16 -> 17 ;\n",
      "18 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 0, 0, 0, 0, 0, 3]\\nclass = 9\", fillcolor=\"#e53958\"] ;\n",
      "16 -> 18 ;\n",
      "{rank=same ; 0} ;\n",
      "{rank=same ; 1; 8} ;\n",
      "{rank=same ; 2; 10} ;\n",
      "{rank=same ; 3; 11; 14} ;\n",
      "{rank=same ; 16} ;\n",
      "{rank=same ; 4; 5; 6; 7; 9; 12; 13; 15; 17; 18} ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, let's see the tree!\n",
    "#\n",
    "\n",
    "filename = 'tree_data.gv'    # sometimes .dot is used, instead of .gv\n",
    "\n",
    "tree.export_graphviz(dtree_model_tuned, out_file=filename,  # the filename constructed above...!\n",
    "                            feature_names=COLUMNS[:-1], # actual feature names, not species\n",
    "                            filled=True,              # fun!\n",
    "                            rotate=False,             # False for Up/Down; True for L/R\n",
    "                            class_names=ClassNames,      # good to have   \n",
    "                            leaves_parallel=True )    # lots of options!\n",
    "\n",
    "print(f\"file {filename} written. Try pasting its contents to  http://viz-js.com/\\n\")\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    all_file_text = f.read()\n",
    "    print(all_file_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a 'final' DT classifier with max depth = 5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our DT to use the \"best\" depth...\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_final = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_final.fit(X_all, y_all)                              # yay!  trained!\n",
    "print(\"Created and trained a 'final' DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# final predictive model (k-nearest-neighbor), with tuned k + ALL data incorporated\n",
    "#\n",
    "\n",
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = dtree_model_final.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    return f\"({predicted_species})\"\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "# Features = eval(input(\"Enter new Features: \"))\n",
    "#\n",
    "Features = [0, 0.19, 0.00, 470, 13.2, 93.5, 60.6, 76.0, 76, 21, 43, 52.0, 3.1, 75.2, 73.2, 0, 0]\n",
    "#result = predictive_model( Features )\n",
    "# print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.22158396 0.2052769  0.2214075  0.35173164]\n",
      "\n",
      "Feature  Precip (in) has    0.00% of the decision-making importance.\n",
      "Feature Max Air Temp (F) has    0.00% of the decision-making importance.\n",
      "Feature Min Air Temp (F) has    0.00% of the decision-making importance.\n",
      "Feature Max Rel Hum (%) has    0.00% of the decision-making importance.\n",
      "Feature Min Rel Hum (%) has    0.00% of the decision-making importance.\n",
      "Feature Avg Wind Speed (mph) has    0.00% of the decision-making importance.\n",
      "Feature           T1 has    0.00% of the decision-making importance.\n",
      "Feature           T2 has   22.16% of the decision-making importance.\n",
      "Feature           T7 has   20.53% of the decision-making importance.\n",
      "Feature          T14 has   22.14% of the decision-making importance.\n",
      "Feature          T21 has   35.17% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# feature importances!\n",
    "\n",
    "print(dtree_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = dtree_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pickle file of the model\n",
    "pickle.dump(dtree_model_final, open(\"MountainModel.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st tree picture: AD4Zone1Bins2000.csv, CV = 0.6226\n",
    "\n",
    "2nd tree picture: AD5Zone1Bins2000.csv CV = 0.6143\n",
    "\n",
    "3rd tree pricture: AD4Zone1Bins3000.csv CV = 0.7779\n",
    "\n",
    "4th tree pricture: AD4Zone1Bins4000.csv CV = 0.8185\n",
    "\n",
    "5th tree pricture: AD4Zone1Bins4000.csv CV = 0.8759"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6303bababa2cfec4792f2b0c1072814fdfa7052137521100bb94425bd832a0f7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
